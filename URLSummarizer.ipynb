{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqzQHd3EvayQpl5grkZetz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnshumanAI/NLP-LLMs/blob/main/URLSummarizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bs4\n",
        "!pip install html5lib\n",
        "!pip install lxml\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMlRRg5JdMha",
        "outputId": "7c75ff09-9786-414c-badb-aa84e16138aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.5)\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.10/dist-packages (1.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib) (0.5.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fHfpnqoOhTmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f4f7fa9-6d70-4c1c-b772-bcc3a62005aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "nltk.download(\"stopwords\")\n",
        "import urllib.request\n",
        "import bs4 as BeautifulSoup\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_article(filename):\n",
        "    file=open(filename, \"r\")\n",
        "    filedata=file.readlines()\n",
        "    article=filedata[0]. split (\".\")\n",
        "    Sentences=[]\n",
        "    for sentence in article:\n",
        "        print (sentence)\n",
        "        Sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \"). split (\" \"))\n",
        "    Sentences.pop()\n",
        "    return Sentences"
      ],
      "metadata": {
        "id": "m-aggNCdhtUd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_similarity(S1,S2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords=[]\n",
        "    S1=[w.lower() for w in S1]\n",
        "    S2=[w.lower() for w in S2]\n",
        "    All_words= list(set(S1+S2))\n",
        "    Vector1=[0]*len(All_words)\n",
        "    Vector2=[0]*len(All_words)\n",
        "    for w in S1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        Vector1[All_words.index(w)]+=1\n",
        "    for w in S2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        Vector2[All_words.index(w)]+=1\n",
        "\n",
        "\n",
        "    return 1-cosine_distance(Vector1, Vector2)"
      ],
      "metadata": {
        "id": "kq5YtM04BcQu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_similarity_matrix(sentences,stop_words):\n",
        "    similarity_matrix=np.zeros((len(sentences),len(sentences)))\n",
        "    for idx1 in range (len(sentences)):\n",
        "        for idx2 in range (len(sentences)):\n",
        "            if idx1==idx2:\n",
        "                continue\n",
        "            similarity_matrix[idx1][idx2]=sentence_similarity(sentences [idx1], sentences [idx2],stop_words)\n",
        "    return similarity_matrix"
      ],
      "metadata": {
        "id": "OEGQOoV5dZod"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wr_pa_ur():\n",
        "    Article=urllib.request.urlopen(input (\"Please give a URL\"))\n",
        "    text=Article.read()\n",
        "    text_parsed=BeautifulSoup.BeautifulSoup(text,\"lxml\")\n",
        "    Paragraphs=text_parsed.find_all(\"p\")\n",
        "    text_content=''\n",
        "    for p in Paragraphs:\n",
        "        text_content+=p.text\n",
        "    article=text_content.split(\".\")\n",
        "    sentences=[]\n",
        "    for sentence in article:\n",
        "        print (sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\",\"\").split(\" \"))\n",
        "    sentences.pop()\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "ywLvtll6iP5_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XWsUcgXTnHH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary():\n",
        "    stop_words=stopwords.words(\"english\")\n",
        "    summarize_text=[]\n",
        "    sentences=wr_pa_ur()\n",
        "    sentence_similarity_matrix=build_similarity_matrix(sentences,stop_words)\n",
        "    sentence_similarity_graph=nx.from_numpy_array(sentence_similarity_matrix)\n",
        "    scores=nx.pagerank(sentence_similarity_graph)\n",
        "    ranked_sentence=sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "    print (\"indices of top ranked_sentence order are\",ranked_sentence)\n",
        "    for i in range(len(ranked_sentence)):\n",
        "        summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "    print (\"summarized text:\\n\",\". \".join(summarize_text))"
      ],
      "metadata": {
        "id": "Iu-_xKwLkpA0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_summary()"
      ],
      "metadata": {
        "id": "zsrCJ2rGnI0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8dc969d-56e7-4e9c-d472-3e9014414533"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please give a URLhttps://llmsecurity.net/\n",
            "LLM security is the investigation of the failure modes of LLMs in use, the conditions that lead to them, and their mitigations\n",
            "Here are links to large language model security content - research, papers, and news - posted by @llm_secGot a tip/link? Open a pull request or send a DM\n",
            "*¬†Demystifying RCE Vulnerabilities in LLM-Integrated Apps üå∂Ô∏èüå∂Ô∏è = extra spicyLast updated on Oct 11, 2023Edit this page¬© 2023 @llm_sec\n",
            " This work is licensed under CC BY 4\n",
            "0\n",
            "Published with Wowchemy ‚Äî the free, open source website builder that empowers creators\n",
            "\n",
            "indices of top ranked_sentence order are [(0.44225940081600196, ['Here', 'are', 'links', 'to', 'large', 'language', 'model', 'security', 'content', '-', 'research,', 'papers,', 'and', 'news', '-', 'posted', 'by', '@llm_secGot', 'a', 'tip/link?', 'Open', 'a', 'pull', 'request', 'or', 'send', 'a', 'DM']), (0.23789356089071714, ['0\\nPublished', 'with', 'Wowchemy', '‚Äî', 'the', 'free,', 'open', 'source', 'website', 'builder', 'that', 'empowers', 'creators']), (0.22893794738419007, ['LLM', 'security', 'is', 'the', 'investigation', 'of', 'the', 'failure', 'modes', 'of', 'LLMs', 'in', 'use,', 'the', 'conditions', 'that', 'lead', 'to', 'them,', 'and', 'their', 'mitigations']), (0.04545454545454546, ['*\\xa0Demystifying', 'RCE', 'Vulnerabilities', 'in', 'LLM-Integrated', 'Apps', 'üå∂Ô∏èüå∂Ô∏è', '=', 'extra', 'spicyLast', 'updated', 'on', 'Oct', '11,', '2023Edit', 'this', 'page¬©', '2023', '@llm_sec']), (0.04545454545454546, ['', 'This', 'work', 'is', 'licensed', 'under', 'CC', 'BY', '4'])]\n",
            "summarized text:\n",
            " Here are links to large language model security content - research, papers, and news - posted by @llm_secGot a tip/link? Open a pull request or send a DM. 0\n",
            "Published with Wowchemy ‚Äî the free, open source website builder that empowers creators. LLM security is the investigation of the failure modes of LLMs in use, the conditions that lead to them, and their mitigations. *¬†Demystifying RCE Vulnerabilities in LLM-Integrated Apps üå∂Ô∏èüå∂Ô∏è = extra spicyLast updated on Oct 11, 2023Edit this page¬© 2023 @llm_sec.  This work is licensed under CC BY 4\n"
          ]
        }
      ]
    }
  ]
}